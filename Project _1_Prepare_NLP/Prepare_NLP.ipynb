{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <h1><center>Task 1</center></h1>\n",
    "\n",
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define a function to analyze the frequency of words in a string \n",
    " - Define a function:\n",
    "     * has a string as an input\n",
    "     * splits the string into a list of tokens by space. \n",
    "         - e.g., \"it's a hello world!!!\" will be split into two tokens [\"it's\", \"a\",\"hello\",\"world!!!\"]   \n",
    "     * if a token starts with or ends with one or more punctuations, remove these punctuations, e.g. \"world<font color=\"red\">!!!</font>\" -> \"world\".(<font color=\"blue\">hint, you can import module *string*, use *string.punctuation* to get a list of punctuations, and then use function *strip()* to remove leading or trailing punctuations </font>) \n",
    "     * remove the space surrounding each token\n",
    "     * only keep tokens with 3 or more characters\n",
    "     * convert all tokens into lower case \n",
    "     * create a dictionary to save the count of each unique word \n",
    "     * sort the dictionary by word count in descending order\n",
    "     * return the sorted dictionary \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "text = '''Although COVID-19 vaccines remain effective in preventing severe disease, recent data suggest their \\\n",
    "effectiveness at preventing infection or severe illness wanes over time, especially in people ages 65 years and older.\\\n",
    "The recent emergence of the Omicron variant further emphasizes the importance of vaccination, boosters, and \\\n",
    "prevention efforts needed to protect against COVID-19. Everyone is still considered fully vaccinated two weeks after their second dose \\\n",
    "in a two-shot series, such as the Pfizer-BioNTech or Moderna vaccines, or two weeks after a single-dose vaccine, \\\n",
    "such as the J&J/Janssen vaccine. Fully vaccinated, however is not the same as optimally protected.  \\\n",
    "To be optimally protected, a person needs to get a booster shot when and if eligible.'''\n",
    "\n",
    "def text_analyzer_q1(text):\n",
    "    \n",
    "    # initialize a list\n",
    "    tokens=[]\n",
    "    \n",
    "    # add your code here\n",
    "    \n",
    "    # split by space (including \\tab and \\n)\n",
    "    tokens = text.split()\n",
    "    # clean up tokens\n",
    "    tokens=[x.strip(' ') for x in tokens]\n",
    "    tokens = [''.join(c for c in c if c not in string.punctuation) for c in tokens ]\n",
    "    def clean(text):\n",
    "            for i in text:\n",
    "                if len(i) < 3:\n",
    "                    text.remove(i)\n",
    "            for a in range(len(text)):\n",
    "                text[a]=text[a].lower()\n",
    "            return text\n",
    "    clean(tokens)\n",
    "    #print(tokens)\n",
    "    # initialize a dict \n",
    "    word_count_dict={}\n",
    "\n",
    "    # count token frequency\n",
    "    set01 = set(tokens)\n",
    "    word_count_dict = {item: tokens.count(item) for item in set01}\n",
    "    word_count_dict\n",
    "    # sort the dict by value\n",
    "    sortedword = sorted(word_count_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    sortedword = dict(sortedword)\n",
    "    return sortedword\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 5,\n",
       " 'and': 3,\n",
       " 'such': 2,\n",
       " 'protected': 2,\n",
       " 'preventing': 2,\n",
       " 'after': 2,\n",
       " 'severe': 2,\n",
       " 'vaccines': 2,\n",
       " 'recent': 2,\n",
       " 'two': 2,\n",
       " 'covid19': 2,\n",
       " 'fully': 2,\n",
       " 'their': 2,\n",
       " 'weeks': 2,\n",
       " 'optimally': 2,\n",
       " 'vaccinated': 2,\n",
       " 'vaccine': 2,\n",
       " 'data': 1,\n",
       " 'everyone': 1,\n",
       " 'however': 1,\n",
       " 'person': 1,\n",
       " 'eligible': 1,\n",
       " 'although': 1,\n",
       " 'remain': 1,\n",
       " 'effective': 1,\n",
       " 'suggest': 1,\n",
       " 'especially': 1,\n",
       " 'shot': 1,\n",
       " 'emergence': 1,\n",
       " 'series': 1,\n",
       " 'needs': 1,\n",
       " 'boosters': 1,\n",
       " 'moderna': 1,\n",
       " 'variant': 1,\n",
       " 'wanes': 1,\n",
       " 'protect': 1,\n",
       " 'against': 1,\n",
       " 'when': 1,\n",
       " 'olderthe': 1,\n",
       " 'be': 1,\n",
       " 'jjjanssen': 1,\n",
       " 'years': 1,\n",
       " 'emphasizes': 1,\n",
       " 'singledose': 1,\n",
       " 'still': 1,\n",
       " 'dose': 1,\n",
       " 'disease': 1,\n",
       " 'further': 1,\n",
       " 'same': 1,\n",
       " 'second': 1,\n",
       " 'time': 1,\n",
       " 'not': 1,\n",
       " 'booster': 1,\n",
       " 'pfizerbiontech': 1,\n",
       " 'over': 1,\n",
       " 'people': 1,\n",
       " 'get': 1,\n",
       " 'illness': 1,\n",
       " 'infection': 1,\n",
       " 'needed': 1,\n",
       " 'effectiveness': 1,\n",
       " 'considered': 1,\n",
       " 'a': 1,\n",
       " 'omicron': 1,\n",
       " 'ages': 1,\n",
       " 'efforts': 1,\n",
       " 'twoshot': 1,\n",
       " 'vaccination': 1,\n",
       " 'importance': 1,\n",
       " 'prevention': 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_analyzer_q1(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. Define a function to analyze a numpy array (4 points)\n",
    " - Assume we have an array $X$ which contains term frequency of each document. In this array, each row presents a document, each column denotes a word, and each value, say $x_{i,j}$,  denotes the frequency of the word $j$ in document $i$. Therefore, if there are  $m$ documents, $n$ words, $X$ has a shape of $(m, n)$.\n",
    " \n",
    " Define a function which:\n",
    "      * Take array $X$ as an input.\n",
    "      * Divides word frequency $x_{i,j}$ by the total number of words in document $i$. Save the result as an array named $tf$ ($tf$ has shape of $(m,n)$).\n",
    "      * Calculate the document frequency $df_j$ for word $j$, e.g. how many documents contain word $j$. Save the result to array $df$ ($df$ shape becomes $(n,)$, it's better to keep the dimensions). Note: for this step you need to first convert the array to binary.\n",
    "      * Calculate $idf_j =  ln(\\frac{|m|}{df_j})+1$. m is the number of documents. The reason is, if a word appears in most documents, it does not have the discriminative power. The inverse of $df$ can downgrade the weight of such words. \n",
    "      * Finally, for each $x_{i,j}$, calculates $tf\\_idf_{i,j} = tf_(i,j) * idf_j$. ($tf\\_idf$ has shape of $(m,n)$).\n",
    "      * Now, please print the following:\n",
    "          * print the index of the longest document\n",
    "          * print the indexes of words with the top 4 largest $df$ values\n",
    "          * for the longest document, print the indexes of words with top 3 largest values in the $tf\\_idf$ array (use the index you got previously). \n",
    "      * Return the $tf\\_idf$ array.\n",
    " - Note, for all the steps, **do not use any loop**. Just use array functions and broadcasting for high performance computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_analyzer_q2(X):\n",
    "    X=pd.DataFrame(X)\n",
    "    # get tf \n",
    "    row_sum = np.sum(X, axis=1) \n",
    "    tf = X.div(row_sum,axis = 0)\n",
    "    \n",
    "    # get df\n",
    "    df_01=np.where(X>0,1,0)\n",
    "    df=np.sum(df_01,axis=0)\n",
    "\n",
    "    # get idf\n",
    "    m=X.shape[0]\n",
    "    idf=np.log(abs(m)/df)+1  \n",
    "    # get tf_idf\n",
    "    tf_idf=idf*tf\n",
    "    \n",
    "    #print index of the longest documents\n",
    "    top_x=X.max(axis=1).idxmax()\n",
    "    print(\"Indexes of the longest documents: {}\".format(top_x))\n",
    "    \n",
    "    #print indexes of words with the top 4 largest ð‘‘ð‘“ values\n",
    "    df = pd.DataFrame(df)\n",
    "    top_df = df.nlargest(3,df.columns.values).index\n",
    "    print(\"Indexes of words with the top 3 largest df values: {}\".format(top_df))\n",
    "    \n",
    "    #return index of top_3 words with largest tf_idf values for the longest document\n",
    "    top = tf_idf.loc[top_x]\n",
    "    top = top.reset_index(drop=True)\n",
    "    top_tf_idf = top.nlargest(3).index.values\n",
    "    print(\"Indexes of words with top 3 largest tf_idf values in the longest document: {}\".format(top_tf_idf))\n",
    "    \n",
    "    return tf_idf.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes of the longest documents: 3\n",
      "Indexes of words with the top 3 largest df values: Int64Index([12, 85, 86], dtype='int64')\n",
      "Indexes of words with top 3 largest tf_idf values in the longest document: [14 11 44]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.11345382, 0.        ,\n",
       "        0.13137614, 0.11345382, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.13043478, 0.11345382, 0.        ,\n",
       "        0.        , 0.        , 0.08331699, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.11345382, 0.06568807, 0.        , 0.11345382,\n",
       "        0.        , 0.        , 0.        , 0.08331699, 0.        ,\n",
       "        0.        , 0.11345382, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.06568807, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.11345382,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.08331699, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.06568807,\n",
       "        0.        , 0.        , 0.06568807, 0.08331699, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.10636031, 0.05318015, 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.10437752, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.10437752, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.04      , 0.        , 0.        ,\n",
       "        0.10437752, 0.10437752, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.10437752, 0.        , 0.10437752, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.10437752, 0.10437752, 0.07665163, 0.10437752,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.10437752, 0.10437752, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.10437752, 0.10437752,\n",
       "        0.        , 0.10437752, 0.10437752, 0.        , 0.        ,\n",
       "        0.        , 0.10437752, 0.        , 0.10437752, 0.        ,\n",
       "        0.        , 0.10437752, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.10437752, 0.        , 0.        , 0.07665163,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04892574, 0.10437752, 0.10437752, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.100363  , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.100363  , 0.100363  ,\n",
       "        0.        , 0.        , 0.03846154, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.20072599, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.100363  ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.100363  , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.100363  , 0.        , 0.100363  , 0.        , 0.        ,\n",
       "        0.20072599, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.100363  , 0.100363  , 0.        , 0.100363  , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.20072599, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.100363  , 0.        ,\n",
       "        0.100363  , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.100363  , 0.        , 0.        , 0.        , 0.20072599,\n",
       "        0.100363  , 0.        , 0.        , 0.100363  , 0.        ,\n",
       "        0.100363  , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.04704398, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.0467388 ,\n",
       "        0.11054822, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.12728965, 0.02439024, 0.        , 0.25457931,\n",
       "        0.        , 0.        , 0.0467388 , 0.        , 0.        ,\n",
       "        0.06364483, 0.        , 0.06364483, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.03684941, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.0467388 , 0.06364483,\n",
       "        0.        , 0.        , 0.        , 0.03684941, 0.12728965,\n",
       "        0.        , 0.        , 0.06364483, 0.        , 0.        ,\n",
       "        0.06364483, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.06364483, 0.12728965, 0.0467388 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.12728965,\n",
       "        0.        , 0.        , 0.06364483, 0.        , 0.03684941,\n",
       "        0.        , 0.        , 0.11054822, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.0934776 ,\n",
       "        0.        , 0.12728965, 0.        , 0.        , 0.06364483,\n",
       "        0.02983277, 0.02983277, 0.        , 0.        , 0.06364483,\n",
       "        0.        ],\n",
       "       [0.09664585, 0.        , 0.        , 0.        , 0.07097373,\n",
       "        0.11191301, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09664585, 0.        , 0.07407407, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.09664585,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09664585, 0.        , 0.0559565 , 0.09664585, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.07097373, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.0559565 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.09664585,\n",
       "        0.        , 0.09664585, 0.09664585, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07097373, 0.        , 0.        ,\n",
       "        0.07097373, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.0559565 ,\n",
       "        0.        , 0.        , 0.0559565 , 0.07097373, 0.        ,\n",
       "        0.        , 0.        , 0.09664585, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.09664585, 0.09664585, 0.        ,\n",
       "        0.04530161, 0.04530161, 0.        , 0.        , 0.        ,\n",
       "        0.09664585]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dtm.csv is a csv file for test. \n",
    "# It contains word counts in a few documents\n",
    "dtm = pd.read_csv(\"dtm-1.csv\")\n",
    "text_analyzer_q2(dtm.values)\n",
    "#The reason the answer here is not 27 but 5 is that the two index values are duplicated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3. Define a function to analyze a dataset using pandas (3 points)\n",
    "\n",
    "- The dataset \"emotion.csv\" contains a number of text and ten types of sentiment scores. Define a function named `emotion_analysis` to do the follows:\n",
    "   * Read \"emotion.csv\" as a dataframe with the first row in the csv file as column names\n",
    "   * Count the number of samples labeled for each emotion (i.e. each value in the column \"emotion). Print the counts.\n",
    "   * Add a column \"length\" that calculates the number of words for each text. (hint: \"apply\" function to split the text by space and then count elements in the resulting list)\n",
    "   * Show the min, max, and mean values of sadness, happiness, and text length for each emotion. Print the results.\n",
    "   * Create a cross tabulation of average anxiety scores. Use \"emotion\" as row index, \"worry\" as column index, and \"length\" as values. Print the table.\n",
    " - This function does not have any return. Just print out the result of each calculation step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Self:\n",
    "def emotion_analysis():\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "# read data\n",
    "    df=pd.read_csv(\"emotion.csv\")\n",
    "    print(df.head(2))\n",
    "\n",
    " # Count the number of samples labeled for each emotion\n",
    "    print(\"===The number of samples labeled for each emotion===\")\n",
    "    print(df[\"emotion\"].value_counts())\n",
    "\n",
    "# Create a new column called \"length\" \n",
    "    df['length'] = df.apply(lambda df: \\\n",
    "        len(df[\"text\"].split(\" \")), axis=1)\n",
    "    #print(df.head(5))\n",
    "\n",
    "# Show the min, max, and mean values\n",
    "    print(\"\\n\")\n",
    "    print(\"=== min, max, and mean values of sadness, happiness, and text length for each emotion===\")\n",
    "    df1 = df[[\"emotion\",\"sadness\",\"happiness\",\"length\"]]\n",
    "    df1.head(3)\n",
    "    grouped= df1.groupby(['emotion'])\n",
    "    print(grouped.agg([np.mean, np.min, np.max]))\n",
    "\n",
    "# get cross tab\n",
    "    print(\"\\n\")\n",
    "    print(\"=== Cross tabulation of length by emotion and worry ===\")\n",
    "    print(pd.crosstab(index=df1.emotion, columns=[df.worry], values=df.length, \\\n",
    "            aggfunc=np.mean ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   worry  emotion  anger  disgust  fear  anxiety  sadness  happiness  \\\n",
      "0      3  Sadness      5        5     3        7        7          2   \n",
      "1      8  Anxiety      6        7     7        8        6          4   \n",
      "\n",
      "   relaxation  desire                                               text  \n",
      "0           4       5  It is less an much an issue of how it affects ...  \n",
      "1           3       1  I am concerned that the true impact of the cur...  \n",
      "===The number of samples labeled for each emotion===\n",
      "Anxiety       1381\n",
      "Sadness        357\n",
      "Relaxation     333\n",
      "Fear           230\n",
      "Anger          107\n",
      "Happiness       39\n",
      "Desire          27\n",
      "Disgust         17\n",
      "Name: emotion, dtype: int64\n",
      "\n",
      "\n",
      "=== min, max, and mean values of sadness, happiness, and text length for each emotion===\n",
      "             sadness           happiness                length           \n",
      "                mean amin amax      mean amin amax        mean amin  amax\n",
      "emotion                                                                  \n",
      "Anger       5.672897    1    9  3.177570    1    8  122.084112   88   374\n",
      "Anxiety     5.719768    1    9  3.333816    1    9  118.066618   59   541\n",
      "Desire      4.148148    1    8  4.925926    2    8  150.259259   89  1018\n",
      "Disgust     4.764706    1    8  3.764706    1    6  108.411765   58   158\n",
      "Fear        6.565217    1    9  3.056522    1    9  118.852174   80   322\n",
      "Happiness   2.666667    1    9  7.230769    4    9  122.461538   92   272\n",
      "Relaxation  2.858859    1    9  5.369369    1    9  119.696697    1   292\n",
      "Sadness     7.436975    2    9  3.112045    1    9  122.117647   85   544\n",
      "\n",
      "\n",
      "=== Cross tabulation of length by emotion and worry ===\n",
      "worry                1           2           3           4           5  \\\n",
      "emotion                                                                  \n",
      "Anger       173.000000  119.750000  106.916667  112.222222  130.500000   \n",
      "Anxiety     121.000000  127.666667  114.277778  118.264706  110.206897   \n",
      "Desire             NaN   91.500000  110.428571  129.750000  119.333333   \n",
      "Disgust            NaN   83.000000         NaN  128.500000  102.000000   \n",
      "Fear               NaN         NaN   99.000000  125.333333  113.857143   \n",
      "Happiness   106.333333  137.833333  117.800000  110.400000  109.500000   \n",
      "Relaxation  114.875000  116.027778  126.075472  115.671642  123.659091   \n",
      "Sadness     105.500000  105.285714  127.578947  113.636364  119.058824   \n",
      "\n",
      "worry                6           7           8           9  \n",
      "emotion                                                     \n",
      "Anger       134.722222  110.360000  109.076923  143.687500  \n",
      "Anxiety     118.209924  118.937247  117.600629  120.335404  \n",
      "Desire      226.625000  137.000000         NaN         NaN  \n",
      "Disgust     107.000000  114.500000         NaN         NaN  \n",
      "Fear        116.454545  118.639344  117.808219  120.891892  \n",
      "Happiness   130.625000  127.200000  114.333333  123.000000  \n",
      "Relaxation  116.724138  122.146341  118.000000  122.400000  \n",
      "Sadness     117.409639  121.627451  139.413043  124.580645  \n"
     ]
    }
   ],
   "source": [
    "emotion_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus question (1 point)\n",
    "1. Suppose your machine learning model returns a list of probabilities as the output. Write a function to do the following:\n",
    "    - Given a threshold, say $th$, if a probability > $th$, the prediction is positive; otherwise, negative\n",
    "    - Compare the prediction with the ground truth labels to calculate the confusion matrix as [[TN, FN],[FP,TP]], where:\n",
    "        * True Positives (TP): the number of correct positive predictions\n",
    "        * False Positives (FP): the number of postive predictives which actually are negatives\n",
    "        * True Negatives (TN): the number of correct negative predictions\n",
    "        * False Negatives (FN): the number of negative predictives which actually are positives\n",
    "    - Calculate **precision** as $TP/(TP+FP)$ and **recall** as $TP/(TP+FN)$\n",
    "    - return precision and recall. \n",
    "2. Call this function with $th$ varying from 0.05 to 0.95 with an increase of 0.05. Plot a line chart to see how precision and recall change by $th$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "prob =np.array([0.28997326, 0.10166073, 0.10759583, 0.0694934 , 0.6767239 ,\n",
    "       0.01446897, 0.15268748, 0.15570522, 0.12159665, 0.22593857,\n",
    "       0.98162019, 0.47418329, 0.09376987, 0.80440782, 0.88361167,\n",
    "       0.21579844, 0.72343069, 0.06605903, 0.15447797, 0.10967575,\n",
    "       0.93020135, 0.06570391, 0.05283854, 0.09668829, 0.05974545,\n",
    "       0.04874688, 0.07562255, 0.11103822, 0.71674525, 0.08507381,\n",
    "       0.630128  , 0.16447478, 0.16914903, 0.1715767 , 0.08040751,\n",
    "       0.7001173 , 0.04428363, 0.19469664, 0.12247959, 0.14000294,\n",
    "       0.02411263, 0.26276603, 0.11377073, 0.07055441, 0.2021157 ,\n",
    "       0.11636899, 0.90348488, 0.10191679, 0.88744523, 0.18938904])\n",
    "\n",
    "truth = np.array([1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0,\n",
    "       0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 1, 0, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_performance(prob, truth, th):\n",
    "       conf = [[0, 0], [0, 0]]\n",
    "\n",
    "       # add your code here\n",
    "       for p in range(len(prob)):\n",
    "               if prob[p] > th:\n",
    "                   prob[p] = 1\n",
    "                   if prob[p] == truth[p]:\n",
    "                       conf[1][1] += 1\n",
    "                   else:\n",
    "                       conf[1][0] += 1\n",
    "               elif prob[p] < th:\n",
    "                   prob[p] = 0\n",
    "                   if prob[p] == truth[p]:\n",
    "                       conf[0][0] += 1\n",
    "                   else :\n",
    "                       conf[0][1] += 1\n",
    "       precision = conf[1][1] / (conf[1][1] + conf[1][0])\n",
    "       recall = conf[1][1] / (conf[1][1] + conf[0][1])\n",
    "       return (precision, recall)\n",
    "#evaluate_performance(prob1,truth1,0.05)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2608695652173913, 1.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test with one value\n",
    "evaluate_performance(prob, truth, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with threhold grid\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          prec       rec\n",
      "0.05  0.260870  1.000000\n",
      "0.10  0.342857  1.000000\n",
      "0.15  0.480000  1.000000\n",
      "0.20  0.705882  1.000000\n",
      "0.25  0.857143  1.000000\n",
      "0.30  0.916667  0.916667\n",
      "0.35  0.916667  0.916667\n",
      "0.40  0.916667  0.916667\n",
      "0.45  0.916667  0.916667\n",
      "0.50  0.909091  0.833333\n",
      "0.55  0.909091  0.833333\n",
      "0.60  0.909091  0.833333\n",
      "0.65  0.900000  0.750000\n",
      "0.70  0.888889  0.666667\n",
      "0.75  1.000000  0.500000\n",
      "0.80  1.000000  0.500000\n",
      "0.85  1.000000  0.416667\n",
      "0.90  1.000000  0.250000\n",
      "0.95  1.000000  0.083333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fce80767310>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiIAAAD4CAYAAADRjo1KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dd3xUVeL+8c9JJyQEQwKhF+kdiQgoYEVAig1FxbKiYO+6+rWuujZc24oKKmDBXmnKWkEFlIQmKEiHAIEAIQRC6pzfHxP3l8VABkhypjzv1ysvMjM3Mw+XkHly77nnGGstIiIiIi6EuQ4gIiIioUtFRERERJxRERERERFnVERERETEGRURERERcSbC1QsnJSXZZs2auXp5ERGRapWenr7DWpvsOoe/cVZEmjVrRlpamquXFxERqVbGmA2uM/gjnZoRERERZ1RERERExBkVEREREXFGRUREREScURERERERZyosIsaYicaY7caYZQd53BhjXjDGrDbGLDXGHFf5MUVERCQY+XJEZDIw4BCPDwRalX6MBl4++lgiIiISCiqcR8RaO8cY0+wQmwwD3rTWWmC+Maa2Maa+tXZrJWWs2JbFsGJGtb1cSIuMgeMuh5pJrpOIhKT5a3cyd/UO1zFCQnRkONef0tJ1jKBXGROaNQQ2lbmdUXrfX4qIMWY03qMmNGnSpBJeulTmrzBnbOU9nxyChbRJcOHb0KCr6zAiIeXbFdsY/WY6xR6LMa7TBL9aMZEqItWgMopIef8dbHkbWmsnABMAUlNTy93miBx3qfdDqt6WRfDeSJh4Jgx5HrqMcJ1IJCTMX7uTa99eSLv6tXjn6hOIj4l0HUmkUlTGVTMZQOMytxsBWyrhecUfNegGY2ZDo+Ph0zHwxd+hpMh1KpGgtmTTbkZNXkCTxFjeuLKHSogElcooIlOBy0qvnukJ5FTr+BCpfjWT4NLPoOf18PMr8OYw2JvlOpVIUFqZmcvlk34hMS6Kt686gcSaUa4jiVQqXy7ffReYB7QxxmQYY0YZY64xxlxTuslMYC2wGngVuK7K0or/CI+AAY/Bua/C5oUwoR9sTnedSiSobNi5j5Gv/0x0RBhTRvWkXq0Y15FEKp3xXuxS/VJTU61W3w0SW5d4x43s3QaDn4FuI10nEgl4W3P2M/yVeewrKOaDMb1oVS/edSQ5SsaYdGttqusc/kYzq8rRq98FRn8PTXrC59fDjNuhuNB1KpGAtXNvASNf+5ndeUW8eeUJKiES1FREpHLUrAMjP4HeN8GC1+CNIZC7zXUqkYCzJ7+Iyyb+Qkb2fl6/PJVOjRJcRxKpUioiUnnCI6D/I3De697TNRP6waYFrlOJBIz9hSWMmryAlZm5vDKyOye0qOM6kkiVUxGRytfpfLjqKwiPgsmDIP0N14lE/F5BcQlj3k4nfUM2z43oyilt67qOJFItVESkaqR08o4baXYSTLsJpt0CxQWuU4n4peISD7e8t5g5f2Tx+LmdGNy5getIItVGRUSqTmwiXPIRnHQrpE+CyYNhj6aYESnL47Hc/cmvfLEsk/vOaseFx1fi8hciAUBFRKpWWDic/hAMfwO2LfeOG9k433UqEb9greXh6b/xUXoGN5/Wiqv6tHAdSaTaqYhI9ehwNlz1NUTGeo+MLHgdHM1hI+Ivnv16FZPnrufKE5tzy+mtXMcRcUJFRKpPvfYw+jtocTLMuA2m3ghF+a5TiTjx2g9reeGbVVyQ2oj7B7fDaDldCVEqIlK9ahwDF78Pfe+ERW95r6rJ2ew6lUi1eu+XjTw643fO6lSfx8/trBIiIU1FRKpfWDiceh9c+DZkrfSOG9kw13UqkWoxbckW7vn0V/q1TubZC7sSHqYSIqEtwnUACWHthkCdVtj3L8FOHsLi5KEUhMe6TuUXrAlnXcogPHXbUbtGJMfERlE7NrL0I4qaUeH6LToAfbtiG7e+v5jjmybyysjuREXod0ERFRFxanlxfZ6OfJLhxU9y6rZpruP4jQhK6Lr5Pe4sGsMMT8+/PB4ZbkioEcUxZcrJMaV/1o6NpHbpYwmx/7/EHBMbRUxkuIO/jQDMX7uTa99eSNv68bx2RSo1ovRvIQIqIuLI9tx8nvnPH7yftonaNSI5ddCrRPRoQkS4fkMEIDeTsPcvY1zGCzzStYjVnW4nO7+EnLwisvMK2b2/iN15hewuvb1pVx6/Zng/Lyj2HPRpoyPCiI+JJNAOpoQbQ2LNKOrERZEUF01SXBR14qKpUzOKpPhokmpGUyfO+3h0hP+9wS/ZtJtRkxfQODGWN688gVoxka4jifgNFRGpVvlFJUz8aR3jvl1NQbGHUSc258ZTW5EQqx/M/yM+hbArpsOXd5OY9jI99qyA8ydCbEqFX5pfVOItK6UlxVteiti933tfbn5xNfwFKldxiYdd+wrZsa+QdTv2sWNvAflF5Reu+JgIkkpLyp/FpU5pefn/93tvJ9SIrPJTXCszc7l80i8kxkXx9qgTSKwZVaWvJxJojHU0l0NqaqpNS0tz8tpS/ay1fLEsk8dm/k5G9n5Ob1eP/xvUlhbJca6j+b+Fb8KM2yE+BS6cAvU7u07kF/YVFLNzbyE79hWwI7eAnfsK2bm3gB17C9mxt4CdewvZuc/75668wnKnrYkMNyTFRVOvVgz1E2KoVyuGlIQYUmrF/Pe+lISYIz6ltWHnPs5/ZR4G+Oia3jSpozFQocwYk26tTXWdw9+oiEiV+zUjh0em/8Yv63fRNiWe+we358SWSa5jBZaMdHh/JOzPhqH/hs7DXScKKMUlHrLziv5bTHaUKSzb9xSwbU8+mXvy2ZaTT27BX48YJdSI9JaThBhSakWTklCDlFoxpCR4S0xKrRgSa0b9z9GVrTn7Gf7KPPYVFPP+mF60rhdfnX9l8UMqIuXTqRmpMtv25DN21ko+XphBYmwUj53TiQuPb6zLFY9Eo+4wZjZ8eAV8chVsXQyn/wPC9V/YFxHhYSTHR5McH13htnsLisnMyfeWkxxvQfnzz2178lmxdQ9Zewv+coQlKiKMerWi/3s0ZfmWPezOK+Kdq09QCRE5BP0Uk0qXX1TCq3PW8vLsNRSXWEb3bcH1p7TUAL2jFVcXLvscZt0L816EzKVw/iSoqaNLlSkuOoKWdeNoWffgpw2LSjxk5Rb89yhK5p4yhSUnn2Wbcyj2WF67PJXOjWpXY3qRwKMiIpXGWsu0pVt58osVbN69nwEdUrhnUFua1qnpOlrwCI+EQU9Bg64w7RaYcLJ3YrgGXV0nCymR4WE0qF2DBrVruI4iEvBURKRSLN60m4enLWfhxt20r1+Lp4d3odexdVzHCl5dL4a67eC9kTDxTBjyPHQZ4TqViMhhUxGRo7I1Zz9PfbmSTxdtJikumqfO68x53RtpHEh1aNDt/48b+XQMbFkE/R/1HjUREQkQKiJyRPIKixk/ey3j56zBY+H6U47l2pNbEhetb6lqVTMJLv0MvnoA5o+DzF9h+GTveBIRkQCgdw05LB6P5fMlm3nyi5Vk7snnrM71uXtAWxonan4EZ8IjYMBj3nEiU28qHTfyFjTs7jqZiEiFVETEZ7v2FTLqjQUs2ribzo0S+PfF3Ti+WaLrWPKnzhdAcpvScSMDYfAz0G2k61QiIoekIiI+sdZyzydLWb55D08P78K53RoSpnEg/qd+Fxj9PXz0N/j8eu+4kTMfhwhNKy4i/kkrjIlPPl64mVnLt3F7/9ac372RSog/q1kHRn4CvW+CBa/BG0Mgd5vrVCIi5VIRkQplZOfx0NTl9GiWyFV9WriOI74Ij4D+j3gXystcChP6waYFrlOJiPyFiogcksdjuePDJVhr+dcFXXRZbqDpeB6M+goiomHSQEif7DqRiMj/0BgROaSJP61j/tpdPHVeZ10ZE6hSOsLV38HHV8G0m2HVV5DQyHWqw1MjEXpdD9FarVkk2KiIyEH9sS2Xp2at5PR29RieGmBvXPK/YhPhkg/hu8cgbSLYEteJDk/+Hlj+KYyYAnWOdZ1GRCqRsQcuIVlNUlNTbVpampPXlooVFns456WfyMzJZ9atfUmKq3jVUpEqs+Y7+OhKb4E673VodYbrRCKHzRiTbq1NdZ3D32iMiJTrhW9WsXzLHh4/t5NKiLh37Cney5JrN4Epw2HOWHD0S5SIVC4VEfmL9A3ZvPT9aoZ3b0T/Dimu44h4HdMUrvwPdBoO3z4K74+EglzXqUTkKPlURIwxA4wxK40xq40xd5fzeBNjzHfGmEXGmKXGmEGVH1WqQ15hMbd/sJgGtWvwwJD2ruOI/K+oWDh3gneStpVfwKunwY5VrlOJyFGosIgYY8KBccBAoD1wkTHmwHeo+4APrLXdgBHAS5UdVKrHP2f8zoZdefxreBfiY7SKq/ghY6DXdXDZZ5C3A1491VtKRCQg+XJEpAew2lq71lpbCLwHDDtgGwvUKv08AdhSeRGluny3cjtTft7I1X1acEKLOq7jiBxa874wejYktoB3R8D3T4DH4zqViBwmX4pIQ2BTmdsZpfeV9RAw0hiTAcwEbizviYwxo40xacaYtKysrCOIK1Ule18hd320lDb14rntjNau44j4pnZjuPJL6HIRfP84vH8J5Oe4TiUih8GXIlLeVJoHDle/CJhsrW0EDALeMsb85bmttROstanW2tTk5OTDTytVwlrLfZ8tY3deIc9c2IWYyHDXkUR8F1kDzn4ZBo6FVf/xnqrJWuk6lYj4yJcikgE0LnO7EX899TIK+ADAWjsPiAGSKiOgVL3PF29hxq9bueX01nRokOA6jsjhMwZOGA2XTfUeEXn1VPh9uutUIuIDX4rIAqCVMaa5MSYK72DUqQdssxE4DcAY0w5vEdG5lwCwZfd+7v98Gd2bHsM1/TRjpQS4Zid6x40ktfaepvn2UY0bEfFzFRYRa20xcAMwC/gd79Uxy40xDxtjhpZudjtwtTFmCfAucIV1NWWr+Mzjsdz50RJKPJZntKCdBIuEhvC3L6DrSO/EZ+9eCPt3u04lIgfh01oz1tqZeAehlr3vgTKf/wacWLnRpKq9MW89P63eyWPndKJpnZqu44hUnsgYGPYiNOwGX/wdXj0FRrwDddu5TiYiB9DMqiFq9fZcnvhiBae2rctFPRpX/AUigcYYOP4quHw6FO7zTn62/DPXqUTkACoiIaioxMNtHywhNiqcJ87rhDE6JSNBrGkv77iReu3hw8vh64fAE2CrD4sEMRWREPTit6tZmpHDY+d0om58jOs4IlWvVn24YgZ0vwJ+fNa7cF7eLtepRAQVkZCzeNNuXvxuNed2a8jATvVdxxGpPhHRMOR5GPwcrJvjHTeSucx1KpGQpyISQvYXlnDb+4upFx/NQ8M6uI4j4kbq3+BvM6EoH14/A5Z97DqRSEhTEQkhT3zxO2t37OPp4V2opQXtJJQ17gFjZkNKZ/joSvjPfVBS7DqVSEhSEQkRP6zK4o15G7jyxOb0bqlJb0WIT4HLp0HqKJj7b5hynsaNiDigIhICcvKKuPPDpbSsG8ddA9q4jiPiPyKiYPAzMPRF2DAXJvSDrUtdpxIJKSoiIeD+z5exY28Bz17QVQvaiZTnuEvhb196T8+83h+Wfug6kUjIUBEJctOWbGHqki3cdForOjXSgnYiB9Wou3fcSMPj4JOr4Mv/07gRkWqgIhLEMnPyue+zZXRtXJvrTtaCdiIViqsLl30OPcbA/HHw1tmwb4frVCJBTUUkSFlruevjpRQUl/DMBV2ICNc/tYhPwiNh0FNw9suw6RcY3w+2LHKdSiRo6d0pSL09fwNz/sji3kHtaJEc5zqOSODpejGMmuVds+b1M2Hxu64TiQQlFZEgtDZrL/+c+Tt9WyczsmdT13FEAleDbjD6e++8I59dAzPvgpIi16lEgoqKSBC677NlREeEM/b8zlrQTuRo1UyCSz+DntfDL+PhzWGwd7vrVCJBQ0UkyCzamM3cNTu58dSW1KulBe1EKkV4BAx4DM59FTYvhAknw+Z016lEgoKKSJAZP3sttWIiGNGjiesoIsGn8wWl40bCYeJAWPiW60QiAU9FJIisydrLrN8yubRXU+KiI1zHEQlO9bt4x4006QlTb4Dpt0FxoetUIgFLRSSIvPbDWiLDw7iid3PXUUSCW806MPIT6H0TpL0ObwyB3G2uU4kEJBWRILF9Tz4fp2/m/O6NSI6Pdh1HJPiFR0D/R+D8iZC51LtOzaYFrlOJBBwVkSAxae56ijweRvdp4TqKSGjpeB6M+goiomHSQEif7DqRSEBREQkCuflFvD1/AwM7ptAsqabrOCKhJ6UjXP0dNO8L0272fhQXuE4lEhBURILAu79sJDe/mDF9tZ6MiDOxiXDJh3DSbd6jIpPPgvw9rlOJ+D0VkQBXUFzC6z+uo1eLOnRpXNt1HJHQFhYOpz8IwydDRhp887DrRCJ+T0UkwH2+eAvb9hRwjVbXFfEfHc6BHqNhwWsawCpSARWRAObxWCbMWUu7+rXo2yrJdRwRKevU+yC+Pky/RevTiByCikgA+2bFdlZv38s1/VpoTRkRfxNTCwaNhW3LYN4412lE/JaKSAAbP3sNDWvX4KxO9V1HEZHytBsMbc6C75+A7PWu04j4JRWRAJW2fhdpG7K5uk9zIsL1zyjitwY95R3EOuN2sNZ1GhG/o3ewAPXK7LUcExvJBcc3dh1FRA4loZF3vMjqr2H5J67TiPgdFZEAtGpbLl//vo3LejUjNkqL24n4vR6joUE3+OJu2J/tOo2IX1ERCUAT5qwlJjKMy3s3cx1FRHwRFg5Dnoe8HfD1Q67TiPgVFZEAszVnP58t3syFqY1JrBnlOo6I+Kp+F+h5nXfW1Y3zXacR8RsqIgFm0k/r8Vi4SovbiQSek++BhMala9EUuk4j4hd8GmBgjBkAPA+EA69Za58oZ5sLgIcACyyx1l5ciTkFyNlfxDs/b+SsTvVpnBjrOo6IHK7oOBj0NLx7Icx9Afre4TqROJaenl43IiLiNaAjwXlwwAMsKy4uvqp79+7by9ugwiJijAkHxgFnABnAAmPMVGvtb2W2aQXcA5xorc02xtStlPjyP6b8vIG9BcWM7qujISIBq80AaD8MZj/lnQq+jpZnCGURERGvpaSktEtOTs4OCwsLuuu7PR6PycrKap+ZmfkaMLS8bXxpXz2A1dbatdbaQuA9YNgB21wNjLPWZgNYa8ttPXLk8otKmPjjevq0SqJjwwTXcUTkaAx4EiKiYfqtmltEOiYnJ+8JxhICEBYWZpOTk3PwHvEpfxsfnqchsKnM7YzS+8pqDbQ2xvxkjJlfeipHKtGnizazY28B1/TTb08iAa9WfTjtAVg3G5Z+4DqNuBUWrCXkT6V/v4P2DV+KSHmLmBy40yKAVsDJwEXAa8aYv6xJb4wZbYxJM8akZWVl+fDSAlBSurhdp4YJ9D62jus4IlIZUkdBw1SYdQ/k7XKdRsQZX4pIBlB2+s5GwJZytvncWltkrV0HrMRbTP6HtXaCtTbVWpuanJx8pJlDzle/ZbJuxz7GaHE7keARFuadWyQ/B76633UakUMqLi6usuf2pYgsAFoZY5obY6KAEcDUA7b5DDgFwBiThPdUzdrKDBqqrLW8PHstTRJjGdhRi9uJBJWUjtDrBlj0Nqz/0XUaCVErV66Mat68eYdzzz23WevWrdsPGDCgRW5ubljDhg073XHHHfW7d+/eZuLEiccsX748uk+fPq06dOjQrnv37m0WLVoUA7Bp06aIM84449g2bdq0b9OmTfuvvvqq5uG8foVXzVhri40xNwCz8F6+O9Fau9wY8zCQZq2dWvpYf2PMb0AJcKe1dufh7gz5q5/X7WLJpt08cnZHwsN0NEQk6PT7Oyz/FKbdAtf+5B3EKiHpzo+WNP4jM7dS52ZonRKfN/b8Lpsq2m79+vUx48ePX9+/f/99w4cPbzZ27NhkgJiYGE96evpKgF69erWeMGHChk6dOhV8++23Na+99tom8+fP/+Oaa65p0qdPn9wHHnhgTXFxMTk5OeGHk9GneUSstTOBmQfc90CZzy1wW+mHVKLxs9eQFBfF8O6NXEcRkaoQFQuDn4G3z4Mfn4WT73adSEJQSkpKYf/+/fcBXHrppTtfeOGFugCXXXZZNkBOTk7YokWL4oYPH/7fKyYKCwsNwNy5c+M/+uijdQARERHUqVOn5HBeWyum+bEVmXv4bmUWd/RvTUzkYRVMEQkkLU+HjufDD/+CDudCcmvXicQBX45cVJUDxx/+eTs+Pt4DUFJSQnx8fPGKFSt+++tXH51gnMUtaEyYvZbYqHBG9mzqOoqIVLUBj0NkDc0tIk5s3bo16uuvv64J8M477yT27t17b9nHExMTPY0aNSqcOHHiMQAej4d58+bVADjxxBNz/zyVU1xczK5duw6rW6iI+KnNu/czdckWLurRhNqxWtxOJOjF1YUzHoYNP8LiKa7TSIhp0aJF/sSJE+u0bt26fXZ2dsQdd9zxlzk23n333bWTJk1KatOmTftWrVp1+Pjjj2sDvPzyyxtnz54d37p16/YdO3Zsv3DhwhqH89o6NeOnXv9hHQCjTmruOImIVJtul8Hid+E/90HrAVAzyXUiCRFhYWG88847G8vet3nz5l/L3m7btm3hDz/8sOrAr23cuHHxN998s+aIX/tIv1Cqzu68Qt5bsJGhXRvQoPZhFUsRCWR/zi1SsBdm3es6jUi1UBHxQ2/N20BeYQlj+mo6d5GQU7ctnHgzLH0P1n7vOo2EgDZt2hSuWrVquavXVxHxM/lFJUyeu55T29alTUq86zgi4kLfOyCxhXfgatF+12lEqpSKiJ/5MD2DnfsKGdO3hesoIuJKZA0Y/CzsWgtznnadRqRKqYj4keISD6/OWUu3JrXp0TzRdRwRcanFydB5BPz0PGz/3XUakSqjIuJHvlyeycZdeYzpe6wWtxMROPOfEB3nnf7d43GdRqRKqIj4CWstr8xeQ4ukmvRvX891HBHxBzWToP+jsGk+LHrTdRqRKqEi4ifmrtnJss17GN23BWFa3E5E/tT1EmjWB756AHK3uU4jQc7j8VBSclhLxRw1FRE/8crsNSTHR3POcQ1dRxERf2KMd+Bq0X6YdY/rNBKEVq5cGdWiRYsOI0eObNKhQ4f2L730Up2uXbu2bd++fbuBAwe2yMnJCQOYPXt2bLdu3dq2adOmfadOndplZ2dXSofQzKp+YNnmHH5YtYO/D2hLdIQWtxORAyS1gj63w/ePQ5eLodXprhNJVfjs+sZs/y22Up+zbvs8zh5X4WJ669evj3n11VfXjx07dsuQIUOOnTNnzh+1atXy3HvvvSmPPPJIvUcffTTzkksuOXbKlClr+vXrl7dr166wuLi4Shm4pCLiB8bPWUtcdASX9GziOoqI+KuTboVfP4IZt8F18yGqct+vJLTVr1+/8LTTTtv37rvvJqxZsyamR48ebQGKiopM9+7d9y5dujSmbt26Rf369csD7yJ4lfXaKiKObdqVx4ylW7i6TwtqxUS6jiMi/ioiGoY8B5PPgjcGQ3z9KniNGG/hSelY+c8tFfPhyEVViY2N9YD3womTTjppz7Rp09aVffznn3+uYYypkmWhVUQce+2HtYSHGa7U4nYiUpFmJ8FpD8CyTyB7feU/f04GrJwJw16EjudV/vOL3zv55JP33X777U2WLVsW3bFjx4Lc3NywdevWRXbp0iV/27ZtUbNnz47t169fXnZ2dlhcXJwnMvLof4FWEXFo594C3k/bxDndGlKvVozrOCISCPrc7v2oCrmZ8MHl8NGVsGURnPYQhOttIpQ0aNCgePz48etHjBjRorCw0AA8+OCDmzt37lwwZcqUNTfddFOT/Pz8sJiYGM+cOXP+SEhIOOpTNPoOc+jNeRvIL/IwWovbiYg/iE+By6d5r86Z+2/I/BXOnwSxmuk5mB246N3QoUNzhw4d+pfpfPv165e3ZMmSFZX9+rp815G8wmLenLeeM9rXo2XdONdxRES8IqLgrH/B0Bdhw1yY0A+2LnWdSoKYiogjj89cQXZeEdf009EQEfFDx10Kf/sSSorh9f6w9APXiSRIqYg4MHXJFt6av4Gr+zSne9NjXMcRESlfo+4wZjY0PA4+uRq+vMdbTEQqkYpINVu9fS93f7yU1KbHcNeAtq7jiIgcWlxduOxzOOEamP8SvHU27NvhOlUw8Xg8nqBe16P073fQQa0qItUor7CY66akUyMynBcvPo7IcO1+EQkA4ZEw8Ek4+xXIWADj+3mvqpHKsCwrKyshWMuIx+MxWVlZCcCyg22jq2aqibWW+z5dxqrte3nryhNISdDluiISYLpeBHXbwvuXwutnwpDnvffJESsuLr4qMzPztczMzI4E58EBD7CsuLj4qoNtoCJSTd5bsIlPFm3mltNbcVKrJNdxRESOTINuMPp7+PAK+Owa75GRM//pPWoih6179+7bgaGuc7gUjO3L7yzbnMODU5fTp1USN57aynUcEZGjUzMJLv0Met0Av4yHN4bC3u2uU0mAUhGpYnvyi7j+nYUkxkbx3IVdCQ8LytOAIhJqwiO8R0LOfc17VGR8P8hId51KApCKSBWy1nLnh0vYnL2fFy/uRp24aNeRREQqV+fhMOo/3mIyaQAsfMt1IgkwKiJV6PUf1zFr+TbuHtiW1GaaIllEglT9zjB6NjTtDVNvgOm3QXGh61QSIFREqkj6hl088cUKzuxQj1FaWVdEgl1sIlzyMfS+CdJehzcGexfRE6mAikgV2Lm3gBveWUSD2jV46vwuGKNxISISAsIjoP8jcP5E74J54/vBpl9cpxI/pyJSyUo8llveX8zOfYW8dMlxJNTQJW0iEmI6ngdXfQ2RMTBpEKRNcp1I/JiKSCV78dvV/LBqBw8N6UDHhgmu44iIuFGvA1z9HTTvC9NvgS//z3Ui8VM+FRFjzABjzEpjzGpjzN2H2O58Y4w1xqRWXsTA8eOqHTz3zR+c260hF/Vo7DqOiIhbsYlwyYeQOgrmj4PV37hOJH6owiJijAkHxgEDgfbARcaY9uVsFw/cBPxc2SEDQWZOPje/t4hWdeN49JyOGvHEyygAAA4ASURBVBciIgIQFg5nPgZ1WsKM26Awz3Ui8TO+HBHpAay21q611hYC7wHDytnuEeApIL8S8wWEohIPN767kP1FJbx0yXHERmnmfBGR/4qMgcHPQvZ6mPOU6zTiZ3wpIg2BTWVuZ5Te91/GmG5AY2vt9ErMFjCenrWSBeuzefzcTrSsG+86joiI/2neF7peAnP/DduWu04jfsSXIlLeOQb73weNCQOeBW6v8ImMGW2MSTPGpGVlZfme0o/9Z3km4+esZWTPJgzr2rDiLxARCVX9H4WYBJh2C3g8rtOIn/CliGQAZUdeNgK2lLkdD3QEvjfGrAd6AlPLG7BqrZ1grU211qYmJycfeWo/sXFnHrd/uITOjRK4f/Bfhs2IiEhZsYnQ/5+Q8Quk65Je8fKliCwAWhljmhtjooARwNQ/H7TW5lhrk6y1zay1zYD5wFBrbVqVJPYT+UUlXPdOOgYYd/FxREeEu44kIuL/uozwnqb5+h+aeVUAH4qItbYYuAGYBfwOfGCtXW6MedgYM7SqA/qrR6b/xrLNe3jmgq40Tox1HUdEJDAYA4Ofg+J8+PKgs0FICPHp8g5r7Uxg5gH3PXCQbU8++lj+7fPFm5ny80bG9GvB6e3ruY4jIhJY6hwLfe+E7x6FLhdD6/6uE4lDmln1MK3enss9n/xKj2aJ3Nm/jes4IiKB6cSbIakNzLgdCve5TiMOqYgchn0FxVzz9kJio8L598XdiAjX7hMROSIRUTDkecjZCN8/7jqNOKR3Uh9Za7n3019Zm7WX50d0o16tGNeRREQCW9NecNzlMO8l2LrUdRpxREXER+/8spHPFm/h1tNbc2LLJNdxRESCwxn/8F7WO+1m8JS4TiMOqIj4YNnmHP4x9Tf6tU7m+lNauo4jIhI8ahwDA56ALQthwWuu04gDKiIVyNlfxLVT0qkTF8WzF3YlLEyL2YmIVKqO58Gxp8I3j0DOZtdppJqpiBxCbn4RN7yzkK2783nx4uNIrBnlOpKISPAxBs56BjzF8MVdrtNINVMROYhV23IZNu4n5q7ZyT/P6Uj3pse4jiQiErwSm8PJf4cV02HFDNdppBqpiJRjxtKtDBv3E3v2FzHlqhO48PgmriOJiAS/XjdA3Q4w804oyHWdRqqJikgZxSUeHpv5O9e/s5C2KfFMv7EPPVvUcR1LRCQ0hEfCkOdgzxb49p+u00g1UREptWNvASNf/5kJc9ZyWa+mvDe6FykJmitERKRaNe4BqVfCL+Nh80LXaaQaqIgACzdmM/iFH1m0cTf/Gt6Fh4d1JCpCu0ZExInTH4Sadb1zi5QUu04jVSyk322ttbw1fwMXjp9HZIThk+t6c173Rq5jiYiEtpgEGPgkZC71HhmRoObT6rvBKL+ohHs/XcbHCzM4pU0yz13YjYTYSNexREQEoP0waHWmd6xIu6FQu7HrRFJFQvKIyKZdeZz38lw+XpjBzae14vXLj1cJERHxJ8bAWU8DFmbeAda6TiRVJOSKyPcrtzP43z+yaVceE69I5dYzWmu2VBERf1S7CZzyf/DHl/D7VNdppIqETBHxeCwvfLOKv01eQP2EGKbdeBKntq3nOpaIiBzKCddCSieYeRfk57hOI1UgJIpIzv4irn4zjWe++oOzuzbk0+tOpGmdmq5jiYhIRcIjYMjzsG+7dy0aCTpBP1j19617uObtdDZn7+cfQztwWa+mGKNTMSIiAaNhd+gxGn4eD50vhMbHu04klSioj4h8vngz57z0E/sLS3h/TE8u791MJUREJBCdeh/E14fpt0BJkes0UomCsogUlXh4aOpybn5vMZ0b1mb6TSfRvWmi61giInKkouNh0FjYtgzmjXOdRipR0J2a2b4nn+umLCRtQzajTmrO3QPbEhkelH1LRCS0tBsMbQfD909Ah7PhmGauE0klCKp36AXrd3HWv39k+ZY9vHBRN+4f3F4lREQkmAx8EsLCYcbtmlskSATFu7S1lkk/reOiCfOJi47gs+tPZGiXBq5jiYhIZUtoBKfeD6u/hmUfu04jlSAoisikn9bzj2m/cUrbunx+w4m0SYl3HUlERKpKj6uhQTf48h7Yn+06jRyloBgjcn5qI8LDDJf2bKpZUkVEgl1YuHdukQmnwNcPeT+XgBUUR0RqxURyee9mKiEiIqGifhfoeS2kT4aN812nkaMQFEVERERC0Mn3QEJjmHYzFBe6TiNHSEVEREQCU3QcDHoaslbA3Bdcp5EjpCIiIiKBq80AaD8MZj8FO9e4TiNHQEVEREQC24AnISIapt+quUUCkIqIiIgEtlr14fQHYd1sWPqB6zRymFREREQk8HW/EhodD7PugbxdrtPIYVARERGRwBcW5p1PJD8HvrrfdRo5DCoiIiISHOp1gN43wqK3Yf2PrtOIj3wqIsaYAcaYlcaY1caYu8t5/DZjzG/GmKXGmG+MMU0rP6qIiEgF+t4FtZvCtFuguMB1GvFBhUXEGBMOjAMGAu2Bi4wx7Q/YbBGQaq3tDHwEPFXZQUVERCoUFQuDn4Gdq+DHZ12nER/4ckSkB7DaWrvWWlsIvAcMK7uBtfY7a21e6c35QKPKjSkiIuKjlqdDx/Phh39B1h+u00gFfCkiDYFNZW5nlN53MKOAL8p7wBgz2hiTZoxJy8rK8j2liIjI4RjwOETW0NwiAcCXIlLeSnLl/qsaY0YCqcDY8h631k6w1qZaa1OTk5N9TykiInI44urCGY/Ahh9h8RTXaeQQfCkiGUDjMrcbAVsO3MgYczpwLzDUWqsRQiIi4la3S6FJL/jPfbBvh+s0chC+FJEFQCtjTHNjTBQwAphadgNjTDdgPN4Ssr3yY4qIiBymsDAY/BwU7IVZ97pOIwdRYRGx1hYDNwCzgN+BD6y1y40xDxtjhpZuNhaIAz40xiw2xkw9yNOJiIhUn7pt4aRbYOl7sOY712mkHMY6GsSTmppq09LSnLy2iIiEkKJ8eLk3WA9cN887iNUBY0y6tTbVyYv7Mc2sKiIiwS0yBgY/C9nrYM7TrtPIAVREREQk+LXoB10ugp+eg+2/u04jZaiIiIhIaOj/T4iu5Z3+3eNxnUZKqYiIiEhoqFkH+j8Km+bDwjdcp5FSKiIiIhI6ul4MzfrAVw9C7jbXaQQVERERCSXGeOcWKd4Ps+5xnUZQERERkVCT1BL63AHLPoZVX7tOE/JUREREJPScdAsktYYZt0JhXsXbS5VRERERkdATEe09RbN7I8x+wnWakKYiIiIioanZid6F8ea+CJm/uk4TslREREQkdJ3xMNQ4pnRukRLXaUKSioiIiISu2EQY8DhsToO0ia7ThCQVERERCW2dhkOLU+Drf8Cera7ThBwVERERCW3GwOBnwFMEX9zlOk3IURERERFJbAH97oLfp8LKL1ynCSkqIiIiIgC9b4K67WHGHVCw13WakKEiIiIiAhAe6Z1bZE8GfPeY6zQhQ0VERETkT01OgNQr4eeXYcti12lCgoqIiIhIWac9CDWTYdrNUFLsOk3QUxEREREpq0ZtGPgk1O8CJQWu0wS9CNcBRERE/E6Hc7wfUuV0REREREScURERERERZ1RERERExBkVEREREXFGRUREREScURERERERZ1RERERExBkVEREREXHGWGvdvLAxWcAGJy8eGpKAHa5DhADt5+qh/Vx9tK+rTlNrbbLrEP7GWRGRqmWMSbPWprrOEey0n6uH9nP10b6W6qZTMyIiIuKMioiIiIg4oyISvCa4DhAitJ+rh/Zz9dG+lmqlMSIiIiLijI6IiIiIiDMqIiIiIuKMikiAM8YMMMasNMasNsbcXc7jtxljfjPGLDXGfGOMaeoiZ6CraD+X2e58Y4w1xujyxyPgy342xlxQ+j293BjzTnVnDAY+/NxoYoz5zhizqPRnxyAXOSU0aIxIADPGhAN/AGcAGcAC4CJr7W9ltjkF+Nlam2eMuRY42Vp7oZPAAcqX/Vy6XTwwA4gCbrDWplV31kDm4/dzK+AD4FRrbbYxpq61druTwAHKx/08AVhkrX3ZGNMemGmtbeYirwQ/HREJbD2A1dbatdbaQuA9YFjZDay131lr80pvzgcaVXPGYFDhfi71CPAUkF+d4YKIL/v5amCctTYbQCXkiPiyny1Qq/TzBGBLNeaTEKMiEtgaApvK3M4ove9gRgFfVGmi4FThfjbGdAMaW2unV2ewIOPL93NroLUx5idjzHxjzIBqSxc8fNnPDwEjjTEZwEzgxuqJJqEownUAOSqmnPvKPddmjBkJpAL9qjRRcDrkfjbGhAHPAldUV6Ag5cv3cwTQCjgZ79G9H4wxHa21u6s4WzDxZT9fBEy21v7LGNMLeKt0P3uqPp6EGh0RCWwZQOMytxtRziFUY8zpwL3AUGttQTVlCyYV7ed4oCPwvTFmPdATmKoBq4fNl+/nDOBza22RtXYdsBJvMRHf+bKfR+Edi4O1dh4Qg3cxPJFKpyIS2BYArYwxzY0xUcAIYGrZDUpPGYzHW0J0Pv3IHHI/W2tzrLVJ1tpmpQP65uPd3xqsengq/H4GPgNOATDGJOE9VbO2WlMGPl/280bgNABjTDu8RSSrWlNKyFARCWDW2mLgBmAW8DvwgbV2uTHmYWPM0NLNxgJxwIfGmMXGmAN/4EgFfNzPcpR83M+zgJ3GmN+A74A7rbU73SQOTD7u59uBq40xS4B3gSusLrGUKqLLd0VERMQZHRERERERZ1RERERExBkVEREREXFGRUREREScURERERERZ1RERERExBkVEREREXHm/wEWY/zSV6FDGAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
